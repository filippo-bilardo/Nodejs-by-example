# Esercitazioni Pratiche - Event Loop in Node.js

## ğŸ“‹ Indice delle Esercitazioni

1. [Esercizio 1: Analisi dell'Ordine di Esecuzione](#esercizio-1-analisi-dellordine-di-esecuzione)
2. [Esercizio 2: Microtask vs Macrotask](#esercizio-2-microtask-vs-macrotask)
3. [Esercizio 3: Event Loop Monitor](#esercizio-3-event-loop-monitor)
4. [Esercizio 4: Ottimizzazione Loop Pesante](#esercizio-4-ottimizzazione-loop-pesante)
5. [Esercizio 5: Worker Threads per Fibonacci](#esercizio-5-worker-threads-per-fibonacci)
6. [Esercizio 6: Task Scheduler con PrioritÃ ](#esercizio-6-task-scheduler-con-prioritÃ )
7. [Esercizio 7: Server Non Bloccante](#esercizio-7-server-non-bloccante)
8. [Esercizio 8: Cluster Mode Load Balancer](#esercizio-8-cluster-mode-load-balancer)
9. [Esercizio 9: Streaming File Processor](#esercizio-9-streaming-file-processor)
10. [Esercizio 10: Async Queue con Rate Limiting](#esercizio-10-async-queue-con-rate-limiting)

---

## Esercizio 1: Analisi dell'Ordine di Esecuzione

### ğŸ¯ Obiettivo
Comprendere l'ordine di esecuzione delle diverse API asincrone in Node.js.

### ğŸ“ Consegna
Scrivi un programma che utilizza tutte le seguenti API asincrone e prevedi l'ordine di esecuzione:
- Codice sincrono (`console.log`)
- `process.nextTick()`
- `Promise.resolve().then()`
- `setTimeout()` con delay 0
- `setImmediate()`
- `queueMicrotask()`

### ğŸ’» Codice Base

```javascript
// es01-execution-order.js

console.log('=== Inizio ===');

setTimeout(() => {
    console.log('6. setTimeout 0ms');
}, 0);

setImmediate(() => {
    console.log('7. setImmediate');
});

process.nextTick(() => {
    console.log('2. nextTick 1');
    
    process.nextTick(() => {
        console.log('3. nextTick 2 (nested)');
    });
});

Promise.resolve()
    .then(() => {
        console.log('4. Promise 1');
        return Promise.resolve();
    })
    .then(() => {
        console.log('5. Promise 2');
    });

queueMicrotask(() => {
    console.log('4.5 queueMicrotask');
});

console.log('=== Fine codice sincrono ===');
```

### âœ… Task

1. **Prima di eseguire:** Scrivi su carta l'ordine previsto di esecuzione
2. **Esegui il codice:** `node es01-execution-order.js`
3. **Confronta:** Il risultato corrisponde alla tua previsione?
4. **Documenta:** Spiega perchÃ© ogni callback Ã¨ stata eseguita in quell'ordine

### ğŸ” Domande di Verifica

1. PerchÃ© `process.nextTick()` viene eseguito prima delle Promise?
2. Cosa succede se annidi 100 `process.nextTick()` uno dentro l'altro?
3. L'ordine tra `setTimeout(0)` e `setImmediate()` Ã¨ garantito? PerchÃ©?

### ğŸ“Š Risultato Atteso

```
=== Inizio ===
=== Fine codice sincrono ===
2. nextTick 1
3. nextTick 2 (nested)
4. Promise 1
4.5 queueMicrotask
5. Promise 2
6. setTimeout 0ms
7. setImmediate
```

---

## Esercizio 2: Microtask vs Macrotask

### ğŸ¯ Obiettivo
Comprendere la differenza tra microtask queue e macrotask queue.

### ğŸ“ Consegna
Crea un programma che dimostra come le microtask vengono sempre svuotate completamente prima di passare alla prossima macrotask.

### ğŸ’» Codice da Completare

```javascript
// es02-micro-macro-task.js

function logWithTimestamp(message) {
    const timestamp = Date.now();
    console.log(`[${timestamp}] ${message}`);
}

// TODO: Completa questo esercizio

// 1. Crea un setTimeout che logga "Macrotask 1"
setTimeout(() => {
    logWithTimestamp('Macrotask 1');
    
    // TODO: Aggiungi qui 3 microtask (nextTick, Promise, queueMicrotask)
    
}, 0);

// 2. Crea un altro setTimeout che logga "Macrotask 2"
setTimeout(() => {
    logWithTimestamp('Macrotask 2');
}, 0);

// 3. Aggiungi una Promise che logga "Initial Microtask"
Promise.resolve().then(() => {
    logWithTimestamp('Initial Microtask');
});

logWithTimestamp('Synchronous code');
```

### âœ… Task

1. Completa il codice inserendo le microtask nei punti TODO
2. Esegui e osserva l'output
3. Modifica il codice per creare una "microtask storm" (10+ microtask annidate)
4. Osserva come questo ritarda l'esecuzione di Macrotask 2

### ğŸ” Domande di Verifica

1. Quante microtask vengono eseguite tra Macrotask 1 e Macrotask 2?
2. Cosa succede se crei microtask ricorsive infinite?
3. Come evitare il "microtask starvation"?

### ğŸ’¡ Suggerimento

Usa `process.hrtime.bigint()` per misurare il tempo preciso tra le esecuzioni.

---

## Esercizio 3: Event Loop Monitor

### ğŸ¯ Obiettivo
Creare un monitor che rileva quando l'Event Loop Ã¨ bloccato.

### ğŸ“ Consegna
Implementa una classe `EventLoopMonitor` che:
- Misura il lag dell'Event Loop ogni secondo
- Emette un warning se il lag supera una soglia
- Tiene traccia delle statistiche (min, max, media)

### ğŸ’» Codice da Implementare

```javascript
// es03-event-loop-monitor.js

class EventLoopMonitor {
    constructor(options = {}) {
        this.threshold = options.threshold || 50; // ms
        this.interval = options.interval || 1000; // ms
        this.monitoring = false;
        this.stats = {
            count: 0,
            totalLag: 0,
            minLag: Infinity,
            maxLag: 0,
            warnings: 0
        };
    }
    
    start() {
        if (this.monitoring) return;
        
        this.monitoring = true;
        this.lastCheck = Date.now();
        this.monitor();
    }
    
    monitor() {
        if (!this.monitoring) return;
        
        // TODO: Implementa la logica di monitoring
        // 1. Calcola il lag confrontando tempo atteso vs tempo reale
        // 2. Aggiorna le statistiche
        // 3. Emetti warning se supera threshold
        // 4. Schedula prossimo check con setInterval
        
    }
    
    stop() {
        this.monitoring = false;
        clearInterval(this.intervalId);
    }
    
    getStats() {
        return {
            ...this.stats,
            avgLag: this.stats.totalLag / this.stats.count || 0
        };
    }
    
    reset() {
        this.stats = {
            count: 0,
            totalLag: 0,
            minLag: Infinity,
            maxLag: 0,
            warnings: 0
        };
    }
}

// Test del monitor
const monitor = new EventLoopMonitor({ threshold: 10 });
monitor.start();

// Simula operazioni che bloccano l'Event Loop
function blockEventLoop(ms) {
    const start = Date.now();
    while (Date.now() - start < ms) {
        // Blocca
    }
}

// Test 1: Operazione normale
setTimeout(() => {
    console.log('âœ… Operazione veloce');
}, 1000);

// Test 2: Operazione bloccante
setTimeout(() => {
    console.log('âš ï¸  Inizio operazione bloccante...');
    blockEventLoop(100); // Blocca per 100ms
    console.log('âš ï¸  Fine operazione bloccante');
}, 2000);

// Stampa statistiche dopo 5 secondi
setTimeout(() => {
    console.log('\nğŸ“Š Statistiche finali:');
    console.log(monitor.getStats());
    monitor.stop();
}, 5000);
```

### âœ… Task

1. Implementa il metodo `monitor()` completo
2. Aggiungi metodi `onWarning()` e `onReport()` come callback personalizzabili
3. Estendi il monitor per tracciare anche la memoria utilizzata
4. Crea un grafico ASCII delle misurazioni

### ğŸ” Domande di Verifica

1. Qual Ã¨ la differenza tra `Date.now()` e `process.hrtime()`?
2. PerchÃ© usiamo `setInterval()` invece di `setTimeout()` ricorsivo?
3. Come misureresti il lag in produzione senza impattare le performance?

### ğŸ“Š Output Atteso

```
âœ… Operazione veloce
âš ï¸  Inizio operazione bloccante...
âš ï¸  Event Loop Lag: 102.45ms (threshold: 10ms)
âš ï¸  Fine operazione bloccante

ğŸ“Š Statistiche finali:
{
  count: 5,
  totalLag: 125.67,
  minLag: 0.23,
  maxLag: 102.45,
  avgLag: 25.13,
  warnings: 1
}
```

---

## Esercizio 4: Ottimizzazione Loop Pesante

### ğŸ¯ Obiettivo
Trasformare un loop CPU-intensive bloccante in uno non bloccante.

### ğŸ“ Consegna
Ottimizza la funzione `processArray()` che elabora milioni di elementi senza bloccare l'Event Loop.

### ğŸ’» Codice da Ottimizzare

```javascript
// es04-optimize-loop.js

// âŒ Versione BLOCCANTE (da migliorare)
function processArrayBlocking(array) {
    console.log(`Processing ${array.length} items (BLOCKING)...`);
    const start = Date.now();
    const results = [];
    
    for (let i = 0; i < array.length; i++) {
        // Simulazione elaborazione pesante
        results.push(Math.sqrt(array[i]) * Math.PI);
    }
    
    console.log(`âœ… Completed in ${Date.now() - start}ms`);
    return results;
}

// âœ… TODO: Implementa versione NON BLOCCANTE
async function processArrayNonBlocking(array, batchSize = 1000) {
    // TODO: Implementa qui
    // 1. Dividi array in batch
    // 2. Processa ogni batch
    // 3. Usa setImmediate() tra un batch e l'altro
    // 4. Mostra progress
}

// Test
const hugeArray = Array.from({ length: 10_000_000 }, (_, i) => i);

// Server HTTP per testare se rimane responsivo
const http = require('http');
const server = http.createServer((req, res) => {
    res.writeHead(200);
    res.end('Server is alive!\n');
});
server.listen(3000, () => {
    console.log('ğŸŒ Server listening on http://localhost:3000');
    console.log('ğŸ“ Apri un altro terminale e prova: curl http://localhost:3000');
});

// Testa versione bloccante
setTimeout(() => {
    console.log('\n--- Testing BLOCKING version ---');
    processArrayBlocking(hugeArray.slice(0, 1_000_000));
}, 2000);

// Testa versione non bloccante
setTimeout(async () => {
    console.log('\n--- Testing NON-BLOCKING version ---');
    await processArrayNonBlocking(hugeArray);
    server.close();
}, 5000);
```

### âœ… Task

1. Implementa `processArrayNonBlocking()` con batching
2. Aggiungi progress reporting (es: "Processed 30% - 3M/10M items")
3. Confronta i tempi di esecuzione delle due versioni
4. Durante l'esecuzione, verifica che il server HTTP rimanga responsivo

### ğŸ” Domande di Verifica

1. Qual Ã¨ il trade-off tra `batchSize` piccolo e grande?
2. PerchÃ© usiamo `setImmediate()` invece di `setTimeout(fn, 0)`?
3. Come cambierebbe l'implementazione con Worker Threads?

### ğŸ’¡ Suggerimenti

```javascript
// Esempio struttura
async function processArrayNonBlocking(array, batchSize = 1000) {
    const results = [];
    const total = array.length;
    
    for (let i = 0; i < total; i += batchSize) {
        const end = Math.min(i + batchSize, total);
        
        // Processa batch
        for (let j = i; j < end; j++) {
            results.push(/* elaborazione */);
        }
        
        // Progress
        const progress = ((end / total) * 100).toFixed(1);
        console.log(`Progress: ${progress}% (${end.toLocaleString()}/${total.toLocaleString()})`);
        
        // Cede controllo all'Event Loop
        await new Promise(resolve => setImmediate(resolve));
    }
    
    return results;
}
```

---

## Esercizio 5: Worker Threads per Fibonacci

### ğŸ¯ Obiettivo
Utilizzare Worker Threads per calcoli CPU-intensive senza bloccare il server.

### ğŸ“ Consegna
Crea un server HTTP che calcola numeri di Fibonacci usando Worker Threads.

### ğŸ’» File da Creare

**fibonacci-server.js** (Main thread)
```javascript
// es05-fibonacci-server.js

const http = require('http');
const { Worker } = require('worker_threads');
const url = require('url');

function runWorker(workerData) {
    return new Promise((resolve, reject) => {
        // TODO: Implementa Worker Thread
        // 1. Crea nuovo Worker('./fibonacci-worker.js')
        // 2. Passa workerData
        // 3. Ascolta eventi: 'message', 'error', 'exit'
        // 4. Resolve/reject Promise
    });
}

const server = http.createServer(async (req, res) => {
    const parsedUrl = url.parse(req.url, true);
    
    if (parsedUrl.pathname === '/fib') {
        const n = parseInt(parsedUrl.query.n) || 10;
        
        if (n < 0 || n > 50) {
            res.writeHead(400);
            res.end('n deve essere tra 0 e 50\n');
            return;
        }
        
        try {
            console.log(`ğŸ“Š Calculating Fibonacci(${n})...`);
            const start = Date.now();
            
            const result = await runWorker(n);
            
            const duration = Date.now() - start;
            console.log(`âœ… Fibonacci(${n}) = ${result} (${duration}ms)`);
            
            res.writeHead(200, { 'Content-Type': 'application/json' });
            res.end(JSON.stringify({
                n,
                result,
                duration,
                worker: 'yes'
            }));
        } catch (err) {
            res.writeHead(500);
            res.end(`Error: ${err.message}\n`);
        }
    } else if (parsedUrl.pathname === '/health') {
        res.writeHead(200);
        res.end('OK - Server is responsive!\n');
    } else {
        res.writeHead(404);
        res.end('Not found\n');
    }
});

server.listen(3000, () => {
    console.log('ğŸš€ Server running on http://localhost:3000');
    console.log('ğŸ“ Try: curl http://localhost:3000/fib?n=40');
    console.log('ğŸ“ Try: curl http://localhost:3000/health');
});
```

**fibonacci-worker.js** (Worker thread)
```javascript
// es05-fibonacci-worker.js

const { parentPort, workerData } = require('worker_threads');

function fibonacci(n) {
    // TODO: Implementa Fibonacci (ricorsivo o iterativo)
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);
}

// TODO: Calcola e invia risultato al parent
const result = fibonacci(workerData);
parentPort.postMessage(result);
```

### âœ… Task

1. Completa l'implementazione di entrambi i file
2. Testa con `curl http://localhost:3000/fib?n=40`
3. In un altro terminale, fai richieste a `/health` mentre il worker calcola
4. Confronta con una versione senza Worker (calcolo nel main thread)
5. **Bonus:** Implementa un Worker Pool per riutilizzare i thread

### ğŸ” Domande di Verifica

1. Cosa succede se fai 5 richieste `/fib?n=45` simultanee?
2. Qual Ã¨ l'overhead di creare un nuovo Worker per ogni richiesta?
3. Come implementeresti un timeout per i worker?

### ğŸ“Š Test di Carico

```bash
# Terminale 1: Avvia server
node es05-fibonacci-server.js

# Terminale 2: Test simultanei
for i in {1..5}; do
  curl "http://localhost:3000/fib?n=40" &
done

# Terminale 3: Verifica responsivitÃ 
while true; do
  curl http://localhost:3000/health
  sleep 1
done
```

---

## Esercizio 6: Task Scheduler con PrioritÃ 

### ğŸ¯ Obiettivo
Creare uno scheduler che esegue task con diversi livelli di prioritÃ .

### ğŸ“ Consegna
Implementa un `PriorityScheduler` che gestisce task HIGH, NORMAL e LOW priority usando le giuste API dell'Event Loop.

### ğŸ’» Codice da Implementare

```javascript
// es06-priority-scheduler.js

class PriorityScheduler {
    constructor() {
        this.queues = {
            HIGH: [],
            NORMAL: [],
            LOW: []
        };
        this.running = false;
    }
    
    /**
     * Aggiunge un task alla coda con prioritÃ 
     * @param {string} priority - 'HIGH', 'NORMAL', 'LOW'
     * @param {Function} task - Funzione da eseguire
     * @param {string} name - Nome descrittivo del task
     */
    schedule(priority, task, name) {
        // TODO: Implementa
        // 1. Valida priority
        // 2. Aggiungi {task, name, addedAt} alla coda appropriata
        // 3. Se non sta giÃ  processando, avvia run()
    }
    
    /**
     * Esegue i task rispettando le prioritÃ 
     */
    run() {
        // TODO: Implementa usando le API corrette
        // HIGH priority -> process.nextTick()
        // NORMAL priority -> queueMicrotask()
        // LOW priority -> setImmediate()
    }
    
    getStats() {
        return {
            high: this.queues.HIGH.length,
            normal: this.queues.NORMAL.length,
            low: this.queues.LOW.length,
            total: this.queues.HIGH.length + 
                   this.queues.NORMAL.length + 
                   this.queues.LOW.length
        };
    }
}

// Test dello scheduler
const scheduler = new PriorityScheduler();

console.log('=== Scheduling tasks ===');

// Schedula task in ordine casuale
scheduler.schedule('LOW', () => {
    console.log('4. ğŸ”µ LOW priority task 1');
}, 'Low task 1');

scheduler.schedule('HIGH', () => {
    console.log('1. ğŸ”´ HIGH priority task 1');
}, 'High task 1');

scheduler.schedule('NORMAL', () => {
    console.log('3. ğŸŸ¡ NORMAL priority task 1');
}, 'Normal task 1');

scheduler.schedule('HIGH', () => {
    console.log('1. ğŸ”´ HIGH priority task 2');
}, 'High task 2');

scheduler.schedule('LOW', () => {
    console.log('4. ğŸ”µ LOW priority task 2');
}, 'Low task 2');

scheduler.schedule('NORMAL', () => {
    console.log('3. ğŸŸ¡ NORMAL priority task 2');
}, 'Normal task 2');

console.log('0. ğŸŸ¢ Synchronous code');
console.log(`ğŸ“Š Queued: ${JSON.stringify(scheduler.getStats())}`);

scheduler.run();
```

### âœ… Task

1. Implementa `schedule()` e `run()`
2. Aggiungi metodo `clear(priority)` per svuotare una coda
3. Aggiungi supporto per task asincroni (async/await)
4. **Bonus:** Implementa rate limiting (max X task al secondo)

### ğŸ” Domande di Verifica

1. PerchÃ© HIGH usa `process.nextTick()` e non `Promise`?
2. Cosa succede se scheduli 1000 task HIGH?
3. Come gestiresti task che generano errori?

### ğŸ“Š Output Atteso

```
=== Scheduling tasks ===
0. ğŸŸ¢ Synchronous code
ğŸ“Š Queued: {"high":2,"normal":2,"low":2,"total":6}
1. ğŸ”´ HIGH priority task 1
1. ğŸ”´ HIGH priority task 2
3. ğŸŸ¡ NORMAL priority task 1
3. ğŸŸ¡ NORMAL priority task 2
4. ğŸ”µ LOW priority task 1
4. ğŸ”µ LOW priority task 2
```

---

## Esercizio 7: Server Non Bloccante

### ğŸ¯ Obiettivo
Convertire un server Express bloccante in uno non bloccante.

### ğŸ“ Consegna
Dato un server con operazioni sincrone bloccanti, ottimizzalo per gestire migliaia di richieste concorrenti.

### ğŸ’» Codice da Ottimizzare

```javascript
// es07-blocking-server.js (VERSIONE BLOCCANTE - DA NON USARE)

const express = require('express');
const fs = require('fs');
const crypto = require('crypto');
const app = express();

app.use(express.json());

// âŒ Endpoint bloccante 1: Lettura file sincrona
app.get('/users', (req, res) => {
    const data = fs.readFileSync('./data/users.json', 'utf8');
    const users = JSON.parse(data);
    res.json(users);
});

// âŒ Endpoint bloccante 2: Hash sincrono
app.post('/hash', (req, res) => {
    const { password } = req.body;
    const hash = crypto.pbkdf2Sync(password, 'salt', 100000, 64, 'sha512');
    res.json({ hash: hash.toString('hex') });
});

// âŒ Endpoint bloccante 3: Elaborazione pesante
app.get('/stats', (req, res) => {
    const data = fs.readFileSync('./data/large-dataset.json', 'utf8');
    const records = JSON.parse(data);
    
    // Calcoli pesanti
    const stats = {
        total: records.length,
        sum: 0,
        avg: 0,
        max: 0,
        min: Infinity
    };
    
    for (let i = 0; i < records.length; i++) {
        stats.sum += records[i].value;
        stats.max = Math.max(stats.max, records[i].value);
        stats.min = Math.min(stats.min, records[i].value);
    }
    
    stats.avg = stats.sum / stats.total;
    
    res.json(stats);
});

app.listen(3000, () => {
    console.log('âŒ BLOCKING Server on port 3000');
});
```

**es07-nonblocking-server.js** (DA IMPLEMENTARE)
```javascript
// es07-nonblocking-server.js

const express = require('express');
const fs = require('fs').promises;
const crypto = require('crypto');
const { promisify } = require('util');
const { Worker } = require('worker_threads');
const app = express();

const pbkdf2Async = promisify(crypto.pbkdf2);

app.use(express.json());

// âœ… TODO: Endpoint non bloccante 1
app.get('/users', async (req, res) => {
    // TODO: Usa fs.promises
});

// âœ… TODO: Endpoint non bloccante 2
app.post('/hash', async (req, res) => {
    // TODO: Usa pbkdf2Async o Worker Thread
});

// âœ… TODO: Endpoint non bloccante 3
app.get('/stats', async (req, res) => {
    // TODO: Usa Worker Thread per calcoli pesanti
});

app.listen(3000, () => {
    console.log('âœ… NON-BLOCKING Server on port 3000');
});
```

### âœ… Task

1. Implementa tutti e 3 gli endpoint in versione non bloccante
2. Crea `stats-worker.js` per l'endpoint `/stats`
3. Crea file di test `data/users.json` e `data/large-dataset.json`
4. Confronta le performance con Apache Bench o autocannon

### ğŸ” Test di Carico

```bash
# Crea dati di test
node create-test-data.js

# Test server bloccante
node es07-blocking-server.js &
autocannon -c 100 -d 10 http://localhost:3000/stats

# Test server non bloccante
node es07-nonblocking-server.js &
autocannon -c 100 -d 10 http://localhost:3000/stats
```

**create-test-data.js**
```javascript
const fs = require('fs');

// Crea users.json
const users = Array.from({ length: 1000 }, (_, i) => ({
    id: i + 1,
    name: `User ${i + 1}`,
    email: `user${i + 1}@example.com`
}));
fs.writeFileSync('./data/users.json', JSON.stringify(users, null, 2));

// Crea large-dataset.json
const dataset = Array.from({ length: 100000 }, (_, i) => ({
    id: i,
    value: Math.random() * 1000
}));
fs.writeFileSync('./data/large-dataset.json', JSON.stringify(dataset));

console.log('âœ… Test data created!');
```

### ğŸ“Š Metriche da Confrontare

- Requests per second
- Latenza media
- Latenza p95/p99
- Timeout errors

---

## Esercizio 8: Cluster Mode Load Balancer

### ğŸ¯ Obiettivo
Implementare un server che scala su tutti i core della CPU usando il modulo cluster.

### ğŸ“ Consegna
Crea un server HTTP in cluster mode che distribuisce il carico su tutti i core disponibili.

### ğŸ’» Codice da Implementare

```javascript
// es08-cluster-server.js

const cluster = require('cluster');
const http = require('http');
const os = require('os');
const numCPUs = os.cpus().length;

if (cluster.isMaster) {
    console.log(`ğŸ¯ Master process ${process.pid} is running`);
    console.log(`ğŸ“Š CPU cores: ${numCPUs}`);
    
    // TODO: Implementa master logic
    // 1. Fork worker per ogni CPU
    // 2. Gestisci eventi 'online', 'exit', 'disconnect'
    // 3. Implementa graceful shutdown
    // 4. Traccia worker attivi e loro statistiche
    
    const workers = new Map();
    
    // Fork workers
    for (let i = 0; i < numCPUs; i++) {
        forkWorker(i);
    }
    
    function forkWorker(id) {
        // TODO: Implementa
    }
    
    // Graceful shutdown
    process.on('SIGTERM', () => {
        // TODO: Implementa
    });
    
    // Worker stats ogni 5 secondi
    setInterval(() => {
        console.log('\nğŸ“Š Worker Stats:');
        // TODO: Mostra statistiche workers
    }, 5000);
    
} else {
    // Worker process
    let requestCount = 0;
    
    const server = http.createServer((req, res) => {
        requestCount++;
        
        // Simula elaborazione
        const delay = Math.random() * 100;
        
        setTimeout(() => {
            res.writeHead(200, { 'Content-Type': 'application/json' });
            res.end(JSON.stringify({
                worker: cluster.worker.id,
                pid: process.pid,
                request: requestCount,
                timestamp: new Date().toISOString()
            }));
        }, delay);
    });
    
    server.listen(3000, () => {
        console.log(`ğŸ‘· Worker ${cluster.worker.id} (PID: ${process.pid}) started`);
    });
    
    // Invia statistiche al master
    setInterval(() => {
        process.send({
            type: 'stats',
            data: {
                requests: requestCount,
                memory: process.memoryUsage(),
                uptime: process.uptime()
            }
        });
    }, 3000);
}
```

### âœ… Task

1. Completa la logica del master process
2. Implementa graceful shutdown
3. Aggiungi auto-restart dei worker che crashano
4. Implementa health check dei worker
5. **Bonus:** Aggiungi comando per aggiungere/rimuovere worker dinamicamente

### ğŸ” Test

```bash
# Avvia server
node es08-cluster-server.js

# In altro terminale: test distribuzione carico
for i in {1..20}; do
  curl http://localhost:3000 &
done

# Verifica distribuzione
curl http://localhost:3000 | jq .worker
```

### ğŸ“Š Output Atteso

```
ğŸ¯ Master process 12345 is running
ğŸ“Š CPU cores: 8
ğŸ‘· Worker 1 (PID: 12346) started
ğŸ‘· Worker 2 (PID: 12347) started
ğŸ‘· Worker 3 (PID: 12348) started
ğŸ‘· Worker 4 (PID: 12349) started
ğŸ‘· Worker 5 (PID: 12350) started
ğŸ‘· Worker 6 (PID: 12351) started
ğŸ‘· Worker 7 (PID: 12352) started
ğŸ‘· Worker 8 (PID: 12353) started

ğŸ“Š Worker Stats:
Worker 1: 15 requests, 45.2 MB memory
Worker 2: 18 requests, 44.8 MB memory
Worker 3: 12 requests, 45.1 MB memory
...
```

---

## Esercizio 9: Streaming File Processor

### ğŸ¯ Obiettivo
Processare file enormi (GB) usando stream senza bloccare l'Event Loop.

### ğŸ“ Consegna
Implementa un processore che legge un file CSV gigante, trasforma i dati e scrive l'output, tutto in streaming.

### ğŸ’» Codice da Implementare

```javascript
// es09-stream-processor.js

const fs = require('fs');
const { Transform, pipeline } = require('stream');
const readline = require('readline');

// âœ… TODO: Implementa Transform stream per elaborazione
class DataProcessor extends Transform {
    constructor(options = {}) {
        super(options);
        this.linesProcessed = 0;
        this.errors = 0;
    }
    
    _transform(chunk, encoding, callback) {
        // TODO: Implementa trasformazione
        // 1. Parse della riga CSV
        // 2. Valida dati
        // 3. Trasforma (es: converti valori, calcola campi derivati)
        // 4. Push risultato
        
        try {
            // Esempio trasformazione
            const line = chunk.toString();
            const processed = this.processLine(line);
            
            this.linesProcessed++;
            
            if (this.linesProcessed % 10000 === 0) {
                console.log(`ğŸ“Š Processed ${this.linesProcessed} lines`);
            }
            
            callback(null, processed + '\n');
        } catch (err) {
            this.errors++;
            callback(err);
        }
    }
    
    processLine(line) {
        // TODO: Implementa logica di elaborazione
        // Esempio: CSV con nome,etÃ ,cittÃ 
        const [name, age, city] = line.split(',');
        
        return JSON.stringify({
            name: name?.trim(),
            age: parseInt(age) || 0,
            city: city?.trim(),
            processedAt: new Date().toISOString()
        });
    }
    
    _flush(callback) {
        console.log(`âœ… Processing complete: ${this.linesProcessed} lines`);
        console.log(`âŒ Errors: ${this.errors}`);
        callback();
    }
}

// âœ… TODO: Implementa funzione principale
async function processLargeFile(inputFile, outputFile) {
    return new Promise((resolve, reject) => {
        console.log(`ğŸš€ Starting processing: ${inputFile}`);
        const start = Date.now();
        
        // TODO: Crea pipeline di stream
        // 1. createReadStream (input)
        // 2. readline per linee
        // 3. DataProcessor transform
        // 4. createWriteStream (output)
        
        const readStream = fs.createReadStream(inputFile);
        const writeStream = fs.createWriteStream(outputFile);
        const processor = new DataProcessor();
        
        const rl = readline.createInterface({
            input: readStream,
            crlfDelay: Infinity
        });
        
        let lineNumber = 0;
        
        rl.on('line', (line) => {
            lineNumber++;
            // Skip header
            if (lineNumber === 1) return;
            
            processor.write(line);
        });
        
        rl.on('close', () => {
            processor.end();
        });
        
        processor.pipe(writeStream);
        
        writeStream.on('finish', () => {
            const duration = Date.now() - start;
            console.log(`âœ… Completed in ${duration}ms`);
            resolve();
        });
        
        writeStream.on('error', reject);
    });
}

// Genera file di test
function generateTestFile(filename, lines = 1000000) {
    console.log(`ğŸ“ Generating test file with ${lines} lines...`);
    const writeStream = fs.createWriteStream(filename);
    
    writeStream.write('name,age,city\n'); // Header
    
    const cities = ['Milano', 'Roma', 'Napoli', 'Torino', 'Palermo'];
    
    for (let i = 0; i < lines; i++) {
        const name = `User${i}`;
        const age = Math.floor(Math.random() * 80) + 18;
        const city = cities[Math.floor(Math.random() * cities.length)];
        
        writeStream.write(`${name},${age},${city}\n`);
        
        if (i % 100000 === 0 && i > 0) {
            console.log(`  Generated ${i} lines...`);
        }
    }
    
    writeStream.end();
    
    return new Promise((resolve) => {
        writeStream.on('finish', () => {
            console.log(`âœ… Test file created: ${filename}`);
            resolve();
        });
    });
}

// Main
async function main() {
    const inputFile = 'large-input.csv';
    const outputFile = 'processed-output.jsonl';
    
    // Genera file di test se non esiste
    if (!fs.existsSync(inputFile)) {
        await generateTestFile(inputFile, 1000000); // 1M righe
    }
    
    // Processa file
    await processLargeFile(inputFile, outputFile);
    
    // Verifica output
    const stats = fs.statSync(outputFile);
    console.log(`ğŸ“Š Output file size: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);
}

main().catch(console.error);
```

### âœ… Task

1. Completa l'implementazione di `DataProcessor`
2. Aggiungi gestione errori robusta
3. Implementa progress bar
4. Aggiungi opzione per filtrare record (es: solo etÃ  > 30)
5. **Bonus:** Implementa backpressure handling

### ğŸ” Domande di Verifica

1. PerchÃ© usare stream invece di `fs.readFile()`?
2. Cosa succede se il disco di output Ã¨ piÃ¹ lento del disco di input?
3. Come gestiresti file compressi (.gz)?

### ğŸ“Š Test Performance

```bash
# Genera file di test (1M righe)
node es09-stream-processor.js

# Monitora memoria durante processing
while true; do
  ps aux | grep node | grep -v grep
  sleep 1
done
```

---

## Esercizio 10: Async Queue con Rate Limiting

### ğŸ¯ Obiettivo
Creare una coda asincrona che limita il numero di operazioni concorrenti e il rate di esecuzione.

### ğŸ“ Consegna
Implementa una `RateLimitedQueue` per gestire API calls con limiti di concorrenza e rate limiting.

### ğŸ’» Codice da Implementare

```javascript
// es10-rate-limited-queue.js

class RateLimitedQueue {
    constructor(options = {}) {
        this.concurrency = options.concurrency || 5;
        this.rateLimit = options.rateLimit || 10; // requests per second
        this.queue = [];
        this.running = 0;
        this.completed = 0;
        this.failed = 0;
        this.rateLimitWindow = [];
    }
    
    /**
     * Aggiunge un task alla coda
     * @param {Function} task - Funzione async da eseguire
     * @returns {Promise} Risolve quando il task Ã¨ completato
     */
    async enqueue(task) {
        return new Promise((resolve, reject) => {
            this.queue.push({
                task,
                resolve,
                reject,
                addedAt: Date.now()
            });
            
            this.process();
        });
    }
    
    /**
     * Processa la coda rispettando limiti
     */
    async process() {
        // TODO: Implementa
        // 1. Controlla se puÃ² eseguire (concurrency + rate limit)
        // 2. Prendi task dalla coda
        // 3. Esegui task
        // 4. Gestisci risultato/errore
        // 5. Richiama process() se ci sono altri task
    }
    
    /**
     * Verifica se puÃ² eseguire rispettando rate limit
     */
    canExecute() {
        // TODO: Implementa
        // 1. Controlla concurrency
        // 2. Controlla rate limit (richieste nell'ultimo secondo)
        // 3. Pulisci vecchie entry da rateLimitWindow
        
        // Pulisci finestra (mantieni solo ultimo secondo)
        const now = Date.now();
        this.rateLimitWindow = this.rateLimitWindow.filter(
            timestamp => now - timestamp < 1000
        );
        
        // Verifica limiti
        const withinConcurrency = this.running < this.concurrency;
        const withinRateLimit = this.rateLimitWindow.length < this.rateLimit;
        
        return withinConcurrency && withinRateLimit;
    }
    
    getStats() {
        return {
            queued: this.queue.length,
            running: this.running,
            completed: this.completed,
            failed: this.failed,
            rateLimitWindow: this.rateLimitWindow.length
        };
    }
}

// ===== TEST =====

// Simula API call
function simulateAPICall(id, duration = 100) {
    return new Promise((resolve) => {
        setTimeout(() => {
            resolve({ id, result: `Success ${id}`, duration });
        }, duration);
    });
}

async function test() {
    console.log('ğŸš€ Starting Rate Limited Queue Test\n');
    
    const queue = new RateLimitedQueue({
        concurrency: 3,    // Max 3 simultanee
        rateLimit: 5       // Max 5 per secondo
    });
    
    // Monitora stats
    const statsInterval = setInterval(() => {
        const stats = queue.getStats();
        console.log(`ğŸ“Š Stats: ${JSON.stringify(stats)}`);
    }, 500);
    
    // Aggiungi 20 task
    const tasks = [];
    for (let i = 1; i <= 20; i++) {
        const task = queue.enqueue(async () => {
            console.log(`â–¶ï¸  Task ${i} started`);
            const result = await simulateAPICall(i, Math.random() * 200);
            console.log(`âœ… Task ${i} completed`);
            return result;
        });
        
        tasks.push(task);
    }
    
    // Attendi completamento
    const results = await Promise.all(tasks);
    
    clearInterval(statsInterval);
    
    console.log(`\nâœ… All tasks completed!`);
    console.log(`ğŸ“Š Final stats: ${JSON.stringify(queue.getStats())}`);
    console.log(`ğŸ“ Results: ${results.length} items`);
}

test().catch(console.error);
```

### âœ… Task

1. Implementa i metodi `process()` e `canExecute()`
2. Aggiungi metodo `clear()` per svuotare la coda
3. Aggiungi evento 'drain' quando la coda si svuota
4. Implementa prioritÃ  dei task
5. **Bonus:** Aggiungi retry automatico per task falliti

### ğŸ” Domande di Verifica

1. Come gestiresti rate limit con finestra sliding invece di finestra fissa?
2. Cosa succede se un task impiega piÃ¹ di 1 secondo?
3. Come implementeresti token bucket algorithm?

### ğŸ“Š Output Atteso

```
ğŸš€ Starting Rate Limited Queue Test

ğŸ“Š Stats: {"queued":17,"running":3,"completed":0,"failed":0,"rateLimitWindow":3}
â–¶ï¸  Task 1 started
â–¶ï¸  Task 2 started
â–¶ï¸  Task 3 started
âœ… Task 1 completed
ğŸ“Š Stats: {"queued":16,"running":3,"completed":1,"failed":0,"rateLimitWindow":4}
â–¶ï¸  Task 4 started
âœ… Task 2 completed
â–¶ï¸  Task 5 started
... (rate limiting in azione)
âœ… All tasks completed!
ğŸ“Š Final stats: {"queued":0,"running":0,"completed":20,"failed":0,"rateLimitWindow":0}
```

---

## ğŸ“ Conclusione

Hai completato tutte le esercitazioni sull'Event Loop! Questi esercizi coprono:

- âœ… Comprensione ordine di esecuzione
- âœ… Microtask vs Macrotask
- âœ… Monitoring e debugging
- âœ… Ottimizzazione codice bloccante
- âœ… Worker Threads
- âœ… Cluster Mode
- âœ… Streaming
- âœ… Rate Limiting

### ğŸ“š Prossimi Passi

1. Studia le Promise e async/await in dettaglio
2. Approfondisci Worker Threads e SharedArrayBuffer
3. Esplora librerie come Bull, Agenda per job queues
4. Studia pattern di scalabilitÃ  (PM2, Kubernetes)

### ğŸ”— Risorse Aggiuntive

- [Node.js Event Loop Docs](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/)
- [libuv Design](http://docs.libuv.org/en/v1.x/design.html)
- [Node.js Best Practices](https://github.com/goldbergyoni/nodebestpractices)

**Buon coding! ğŸš€**
